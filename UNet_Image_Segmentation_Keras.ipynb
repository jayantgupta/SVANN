{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n@author: Jayant Gupta\\nlast update: 02.06.2021\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "@author: Jayant Gupta\n",
    "last update: 02.06.2021\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import models\n",
    " \n",
    "from tqdm import tqdm \n",
    "import json\n",
    "\n",
    "from skimage.io import imread, imshow, show\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Handles reading large number of files.\n",
    "Image.MAX_IMAGE_PIXELS = 219494175 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['datasets/MN_raster_Hennepin_North\\\\120_23_13_01.tif', 'datasets/MN_Hennepin_North_vi\\\\120_23_13_01_ExG.tif', 'outputs/MN_raster_Hennepin_North_Mask\\\\120_23_13_01_mask.jpeg']\n['datasets/MN_raster_Hennepin_North\\\\120_23_13_02.tif', 'datasets/MN_Hennepin_North_vi\\\\120_23_13_02_ExG.tif', 'outputs/MN_raster_Hennepin_North_Mask\\\\120_23_13_02_mask.jpeg']\n['datasets/MN_raster_Hennepin_North\\\\120_23_13_03.tif', 'datasets/MN_Hennepin_North_vi\\\\120_23_13_03_ExG.tif', 'outputs/MN_raster_Hennepin_North_Mask\\\\120_23_13_03_mask.jpeg']\n['datasets/MN_raster_Hennepin_North\\\\120_23_13_04.tif', 'datasets/MN_Hennepin_North_vi\\\\120_23_13_04_ExG.tif', 'outputs/MN_raster_Hennepin_North_Mask\\\\120_23_13_04_mask.jpeg']\n['datasets/MN_raster_Hennepin_North\\\\120_23_14_01.tif', 'datasets/MN_Hennepin_North_vi\\\\120_23_14_01_ExG.tif', 'outputs/MN_raster_Hennepin_North_Mask\\\\120_23_14_01_mask.jpeg']\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed = seed\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 4\n",
    "IMG_INDEX = \"ExG\"\n",
    "\n",
    "# This function creates a dictionary to store images and their mask.\n",
    "# This function is curated to handle train images *.tif format and \n",
    "# mask file in *.jpeg format\n",
    "def get_in_out_dict(Image_Path, Mask_Path, Index_Path=None, Index_Type=None):\n",
    "    img_fns = os.listdir(Image_Path)\n",
    "    mask_fns = os.listdir(Mask_Path)\n",
    "\n",
    "    if IMG_CHANNELS > 3:\n",
    "        indices_fns = os.listdir(Index_Path)\n",
    "\n",
    "    in_out_dict = {}\n",
    "    for img_filename in img_fns:\n",
    "        key = img_filename.split('.')[0]\n",
    "        in_out_dict[key] = []\n",
    "        in_out_dict[key].append(\n",
    "            os.path.join(Image_Path, img_filename))\n",
    "        if IMG_CHANNELS > 3:\n",
    "            in_out_dict[key].append(\n",
    "                os.path.join(Index_Path, [index for index in indices_fns if key in index and Index_Type in index][0]))\n",
    "        in_out_dict[key].append(\n",
    "            os.path.join(Mask_Path, [mask for mask in mask_fns if key in mask][0]))\n",
    "    \n",
    "    for key in list(in_out_dict.keys())[0:5]:\n",
    "        print(in_out_dict[key])\n",
    "\n",
    "    return in_out_dict\n",
    "\n",
    "# #train_mask_pair = {**train_mask_mpls_pair, **train_mask_stp_pair} # For OSFA\n",
    "# #test_mask_pair = {**test_mask_mpls_pair, **test_mask_stp_pair}    # For OSFA \n",
    "Mask_Path = json.load(open('config.json'))['filepaths']['default_mask_folder']\n",
    "Image_Path = json.load(open('config.json'))['filepaths']['input_imagery_dir']\n",
    "in_out_dict = {}\n",
    "if IMG_CHANNELS > 3:\n",
    "    Index_Path = json.load(open('config.json'))['filepaths']['input_vi_dir']\n",
    "    in_out_dict = get_in_out_dict(Image_Path, Mask_Path, Index_Path, IMG_INDEX)\n",
    "else:\n",
    "    in_out_dict = get_in_out_dict(Image_Path, Mask_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]Resizing training images and masks\n",
      "120_23_13_01\n",
      "  3%|▎         | 1/36 [00:04<02:29,  4.27s/it]120_23_13_02\n",
      "  6%|▌         | 2/36 [00:09<02:34,  4.54s/it]120_23_13_03\n",
      "  8%|▊         | 3/36 [00:13<02:27,  4.48s/it]120_23_13_04\n",
      " 11%|█         | 4/36 [00:17<02:19,  4.35s/it]120_23_14_01\n",
      " 14%|█▍        | 5/36 [00:22<02:16,  4.41s/it]120_23_14_02\n",
      " 17%|█▋        | 6/36 [00:26<02:10,  4.36s/it]120_23_14_03\n",
      " 19%|█▉        | 7/36 [00:30<02:06,  4.36s/it]120_23_14_04\n",
      " 22%|██▏       | 8/36 [00:35<02:01,  4.35s/it]120_23_15_01\n",
      " 25%|██▌       | 9/36 [00:39<01:57,  4.35s/it]120_23_15_02\n",
      " 28%|██▊       | 10/36 [00:43<01:54,  4.41s/it]120_23_15_03\n",
      " 31%|███       | 11/36 [00:51<02:13,  5.34s/it]120_23_15_04\n",
      " 33%|███▎      | 12/36 [00:56<02:09,  5.40s/it]120_23_22_01\n",
      " 36%|███▌      | 13/36 [01:01<01:58,  5.16s/it]120_23_22_02\n",
      " 39%|███▉      | 14/36 [01:06<01:51,  5.06s/it]120_23_22_03\n",
      " 42%|████▏     | 15/36 [01:17<02:24,  6.86s/it]120_23_22_04\n",
      " 44%|████▍     | 16/36 [01:23<02:14,  6.74s/it]120_23_23_01\n",
      " 47%|████▋     | 17/36 [01:31<02:11,  6.91s/it]120_23_23_02\n",
      " 50%|█████     | 18/36 [01:37<02:03,  6.87s/it]120_23_23_03\n",
      " 53%|█████▎    | 19/36 [01:44<01:53,  6.70s/it]120_23_23_04\n",
      " 56%|█████▌    | 20/36 [01:51<01:48,  6.77s/it]120_23_24_01\n",
      " 58%|█████▊    | 21/36 [01:57<01:40,  6.67s/it]120_23_24_02\n",
      " 61%|██████    | 22/36 [02:03<01:31,  6.55s/it]120_23_24_03\n",
      " 64%|██████▍   | 23/36 [02:10<01:26,  6.64s/it]120_23_24_04\n",
      " 67%|██████▋   | 24/36 [02:16<01:18,  6.52s/it]120_23_25_01\n",
      " 69%|██████▉   | 25/36 [02:23<01:12,  6.55s/it]120_23_25_02\n",
      " 72%|███████▏  | 26/36 [02:30<01:06,  6.62s/it]120_23_25_03\n",
      " 75%|███████▌  | 27/36 [02:36<00:59,  6.57s/it]120_23_25_04\n",
      " 78%|███████▊  | 28/36 [02:41<00:49,  6.15s/it]120_23_26_01\n",
      " 81%|████████  | 29/36 [02:46<00:40,  5.73s/it]120_23_26_02\n",
      " 83%|████████▎ | 30/36 [02:51<00:32,  5.43s/it]120_23_26_03\n",
      " 86%|████████▌ | 31/36 [02:56<00:26,  5.32s/it]120_23_26_04\n",
      " 89%|████████▉ | 32/36 [03:01<00:20,  5.18s/it]120_23_27_01\n",
      " 92%|█████████▏| 33/36 [03:05<00:14,  4.89s/it]120_23_27_02\n",
      " 94%|█████████▍| 34/36 [03:09<00:09,  4.73s/it]120_23_27_03\n",
      " 97%|█████████▋| 35/36 [03:14<00:04,  4.65s/it]120_23_27_04\n",
      "100%|██████████| 36/36 [03:19<00:00,  5.53s/it]\n"
     ]
    }
   ],
   "source": [
    "def join_image_and_index(img_path, index_path):\n",
    "    image = Image.open(img_path) # Using Pillow Image object\n",
    "    image = image.resize((IMG_HEIGHT, IMG_WIDTH)) # \n",
    "    image_array = np.asarray(image)/255.\n",
    "\n",
    "    index = Image.open(index_path) # Using Pillow Image object\n",
    "    index = index.resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "    index_array = np.asarray(index)\n",
    "    return np.dstack((image_array, index_array))\n",
    "\n",
    "# Function to read the data from image_mask_pair file paths.\n",
    "def read_data(in_out_dict):\n",
    "    X_train = np.zeros((len(in_out_dict), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
    "    Y_train = np.zeros((len(in_out_dict), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "    keys = in_out_dict.keys()\n",
    "\n",
    "    print('Resizing training images and masks')\n",
    "    n = 0\n",
    "    for key, value in tqdm(in_out_dict.items()):\n",
    "        print(key)\n",
    "        if IMG_CHANNELS > 3:\n",
    "            [img_path, index_path, mask_path] = value\n",
    "            X_train[n] = join_image_and_index(img_path, index_path)\n",
    "        else:\n",
    "            [img_path, mask_path] = value\n",
    "            image = Image.open(img_path) # Using Pillow Image object\n",
    "            image = image.resize((IMG_HEIGHT, IMG_WIDTH)) # \n",
    "            X_train[n] = np.asarray(image)/255.\n",
    "        mask = Image.open(mask_path) # Using Pillow Image object\n",
    "        mask = mask.resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "        mask = np.array(mask)\n",
    "        mask = mask.reshape(256, 256, 1)\n",
    "        mask_bool = mask > 0          \n",
    "        Y_train[n] = mask_bool \n",
    "        n += 1\n",
    "    return X_train, Y_train\n",
    "\n",
    "X_train_in, Y_train_in = read_data(in_out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Size = 28, Test size = 4, Validation size = 4\n['X_train', 'Y_train', 'X_val', 'Y_val', 'X_test', 'Y_test']\n"
     ]
    }
   ],
   "source": [
    "# Need to run once. Generate training, validation, and test dataset.\n",
    "def generate_train_val_test(X_train, Y_train):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 1)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.12, random_state = 1)\n",
    "    print(\"Train Size = {0}, Test size = {1}, Validation size = {2}\".format(len(X_train), len(X_test), len(X_val)))\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "X_train_split, Y_train_split, X_val, Y_val, X_test, Y_test = generate_train_val_test(X_train_in, Y_train_in)\n",
    "\n",
    "outfile = json.load(open('config.json'))['filepaths']['default_pyobjects'] + '/Hennepin_North.npz'\n",
    "np.savez(outfile ,X_train=X_train_split, Y_train=Y_train_split, X_val=X_val, Y_val=Y_val, X_test=X_test, Y_test=Y_test)\n",
    "npzfile = np.load(outfile)\n",
    "print(npzfile.files)\n",
    "X_train = npzfile['X_train']\n",
    "Y_train = npzfile['Y_train']\n",
    "X_test = npzfile['X_test']\n",
    "Y_test = npzfile['Y_test']\n",
    "X_val = npzfile['X_val']\n",
    "Y_val = npzfile['Y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Samples the input data.\n",
    "for (X, Y, Title) in [(X_train, Y_train, \"Train\"), (X_test, Y_test, \"Test\"), (X_val, Y_val, \"Validation\")]:\n",
    "    print(\"Sampling the \" + Title + \" data\")\n",
    "    image_x = random.randint(0, len(X)-1)\n",
    "    plt.imshow(X[image_x][:,:,:3])\n",
    "    plt.title(\"RGB for \"+Title)\n",
    "    plt.figure()\n",
    "    for c in range(IMG_CHANNELS-3):\n",
    "        art = plt.imshow(X[image_x][:,:,3:4+c], cmap ='plasma')\n",
    "        plt.colorbar(art)\n",
    "        plt.title(\"VI for \"+Title+\" (\"+IMG_INDEX+\")\")\n",
    "        plt.figure()\n",
    "    plt.imshow(np.squeeze(Y[image_x]))\n",
    "    plt.title(\"Mask label for \"+Title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#class CustomCallback(keras.callbacks.Callback):\n",
    "#    def on_train_batch_begin(self, batch, logs=None):\n",
    "#        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "#            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "#        lr = float(tf.keras.backend.get_value(self.model.optimizer_learning_rate))\n",
    "# sample_weights        \n",
    "\n",
    "# Generate a UNetS model\n",
    "unets_model = models.UNetS(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=json.load(open('config.json'))['filepaths']['default_checkpoints'] + '/MPLS-UNetS.h5', verbose=1, save_best_only=True)]\n",
    "\n",
    "# Check sample weighting\n",
    "sample_weight = np.ones(shape=(len(Y_train),))\n",
    "\n",
    "results = unets_model.fit(X_train, Y_train, sample_weight = sample_weight, validation_data=(X_val, Y_val), batch_size=8, epochs=10, callbacks=callbacks)\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a UNet model\n",
    "unet_model = models.UNet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "################################\n",
    "\n",
    "#class CustomCallback(keras.callbacks.Callback):\n",
    "#    def on_train_batch_begin(self, batch, logs=None):\n",
    "#        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "#            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "#        lr = float(tf.keras.backend.get_value(self.model.optimizer_learning_rate))\n",
    "# sample_weights        \n",
    "\n",
    "#Modelcheckpoint\n",
    "#checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/Users/jayantgupta/SVANN/model_for_nuclei.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=json.load(open('config.json'))['filepaths']['default_checkpoints'] + '/MPLS-UNet.h5', verbose=1, save_best_only=True)]\n",
    "\n",
    "# Check sample weighting\n",
    "#sample_weight = np.ones(shape=(len(Y_train),))\n",
    "\n",
    "results = unet_model.fit(X_train, Y_train, sample_weight = sample_weight, validation_split=0.1, batch_size=16, epochs=3, callbacks=callbacks)\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001404571E670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n"
     ]
    }
   ],
   "source": [
    "unets_model = models.UNetS(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "weight_file = json.load(open('config.json'))['filepaths']['default_checkpoints']+'/'+IMG_INDEX+'/MPLS-UNetS.h5'\n",
    "unets_model.load_weights(weight_file)\n",
    "\n",
    "THRESHOLD_TYPE = ['match', 'mean', 'median', 'static']\n",
    "preds_train = unets_model.predict(X_train, verbose=1)\n",
    "preds_val = unets_model.predict(X_val, verbose=1)\n",
    "preds_test = unets_model.predict(X_test, verbose=1)\n",
    "\n",
    "for threshold_type in THRESHOLD_TYPE:\n",
    "    threshold_train=np.percentile(preds_train, (1-np.mean(Y_train.reshape(Y_train.shape[0], Y_train.shape[1]*Y_train.shape[2]), axis=1))*100)\n",
    "    threshold_val=np.percentile(preds_val, (1-np.mean(Y_val.reshape(Y_val.shape[0], Y_val.shape[1]*Y_val.shape[2]), axis=1))*100)\n",
    "    threshold_test=np.percentile(preds_test, (1-np.mean(Y_test.reshape(Y_test.shape[0], Y_test.shape[1]*Y_test.shape[2]), axis=1))*100)\n",
    "\n",
    "    threshold_mean = np.mean(threshold_train)\n",
    "    threshold_median = np.median(threshold_train)\n",
    "\n",
    "    if threshold_type=='mean':\n",
    "        threshold_train = np.full(len(preds_train), threshold_mean)\n",
    "        threshold_val = np.full(len(preds_val), threshold_mean)\n",
    "        threshold_test = np.full(len(preds_test), threshold_mean)\n",
    "    elif threshold_type=='median':\n",
    "        threshold_train = np.full(len(preds_train), threshold_median)\n",
    "        threshold_val = np.full(len(preds_val), threshold_median)\n",
    "        threshold_test = np.full(len(preds_test), threshold_median)\n",
    "    elif threshold_type=='static':\n",
    "        threshold_train = np.full(len(preds_train), 0.2)\n",
    "        threshold_val = np.full(len(preds_val), 0.2)\n",
    "        threshold_test = np.full(len(preds_test), 0.2)\n",
    "\n",
    "    preds_train_t = (np.squeeze(preds_train) > threshold_train[:, None, None]).astype(np.uint8)\n",
    "    preds_val_t = (np.squeeze(preds_val) > threshold_val[:, None, None]).astype(np.uint8)\n",
    "    preds_test_t = (np.squeeze(preds_test) > threshold_test[:, None, None]).astype(np.uint8)\n",
    "\n",
    "    # Perform a sanity check on some random training samples\n",
    "    for ix in range(len(preds_train_t)):\n",
    "        plt.ioff()\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(16, 10), squeeze=True)\n",
    "        fig.suptitle('%s with %s threshold: %0.3f' % (IMG_INDEX, threshold_type, threshold_train[ix]))\n",
    "        axs[0, 0].imshow(X_train[ix][:,:,:3])\n",
    "        axs[0, 0].set_title(\"Input imagery\")\n",
    "        axs[0, 1].imshow(X_train[ix][:,:,3:4])\n",
    "        axs[0, 1].set_title(\"Input index\")\n",
    "        axs[0, 2].imshow(Y_train[ix])\n",
    "        axs[0, 2].set_title(\"Binary mask label\")\n",
    "        axs[1, 0].imshow(preds_train[ix])\n",
    "        axs[1, 0].set_title('Prediction values')\n",
    "        axs[1, 1].imshow(preds_train_t[ix])\n",
    "        axs[1, 1].set_title('Binary prediction')\n",
    "        cm = np.squeeze(Y_train[ix]).astype(int)-2*np.squeeze(preds_train_t[ix]).astype(int)\n",
    "        tn_, fp_, fn_, tp_ = confusion_matrix(Y_train[ix].astype(int).flatten(), preds_train_t[ix].astype(int).flatten(), labels=[0,1]).ravel()\n",
    "        precision = tp_/(tp_+fp_)\n",
    "        recall = tp_/(tp_+fn_)\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "        axs[1, 2].imshow(cm, cmap='RdBu', interpolation='gaussian')\n",
    "        axs[1, 2].set_title('Confusion Matrix (f1: %0.3f)\\nLight Red=tp, Light Blue=tn, Red=fp, Blue=fn' % (f1))\n",
    "        plt.savefig('outputs/plots/'+str(ix)+'/UNetS_'+IMG_INDEX+'_'+threshold_type+'_'+str(ix))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(X_val)-1)\n",
    "imshow(X_val[ix][:,:,:3])\n",
    "plt.title(\"Input imagery\")\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_val[ix]))\n",
    "plt.title(\"Binary mask label\")\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.title('Binary prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tn = 0.\n",
    "fp = 0.\n",
    "fn = 0.\n",
    "tp = 0.\n",
    "for ix in range(0, len(preds_test_t)):\n",
    "    tn_, fp_, fn_, tp_ = confusion_matrix(Y_test[ix].astype(int).flatten(), preds_test_t[ix].astype(int).flatten(), labels=[0,1]).ravel()\n",
    "    tn = tn + tn_\n",
    "    fp = fp + fp_\n",
    "    fn = fn + fn_\n",
    "    tp = tp + tp_\n",
    "\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tn = 0.\n",
    "fp = 0.\n",
    "fn = 0.\n",
    "tp = 0.\n",
    "for ix in range(0, len(preds_val_t)):\n",
    "    #print(ix)\n",
    "    tn_, fp_, fn_, tp_ = confusion_matrix(Y_val[ix].astype(int).flatten(), preds_val_t[ix].astype(int).flatten(), labels=[0,1]).ravel()\n",
    "    tn = tn + tn_\n",
    "    fp = fp + fp_\n",
    "    fn = fn + fn_\n",
    "    tp = tp + tp_\n",
    "#    print(tn, fp, fn, tp)\n",
    "\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting test data samples\n",
    "# Need to run once at the start\n",
    "# print(img_mask_HCL_pair.keys)\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# TEST_HCL_PATH = '/Users/jayantgupta/Desktop/Imagery/Wetland_Imagery/027_23_05_020/Test/img'\n",
    "# TEST_HCL_MASK_PATH = '/Users/jayantgupta/Desktop/Imagery/Wetland_Imagery/027_23_05_020/Test/mask'\n",
    "\n",
    "# TEST_HCR_PATH = '/Users/jayantgupta/Desktop/Imagery/Wetland_Imagery/027_23_05_021/Test/img'\n",
    "# TEST_HCR_MASK_PATH = '/Users/jayantgupta/Desktop/Imagery/Wetland_Imagery/027_23_05_021/Test/mask'\n",
    "\n",
    "# test_samples_HCL = random.choices(list(img_mask_HCL_pair.keys()), k=98)\n",
    "# for sample in test_samples_HCL:\n",
    "#     try:\n",
    "#         img_path = img_mask_HCL_pair[sample][0]\n",
    "#         img_test_path = os.path.join(TEST_HCL_PATH,img_path.split('/')[-1])\n",
    "#         shutil.move(img_path, img_test_path)\n",
    "#     #print(img_path)\n",
    "#     #print(img_test_path)\n",
    "\n",
    "#         mask_path = img_mask_HCL_pair[sample][1]\n",
    "#         mask_test_path = os.path.join(TEST_HCL_MASK_PATH, mask_path.split('/')[-1])\n",
    "#         shutil.move(mask_path, mask_test_path)\n",
    "#     except:\n",
    "#         print(sample)\n",
    "#     #break;\n",
    "\n",
    "# test_samples_HCR = random.choices(list(img_mask_HCR_pair.keys()), k=98)\n",
    "# for sample in test_samples_HCR:\n",
    "#     try:\n",
    "#         img_path = img_mask_HCR_pair[sample][0]\n",
    "#         img_test_path = os.path.join(TEST_HCR_PATH,img_path.split('/')[-1])\n",
    "#         shutil.move(img_path, img_test_path)\n",
    "    \n",
    "#         mask_path = img_mask_HCR_pair[sample][1]\n",
    "#         mask_test_path = os.path.join(TEST_HCR_MASK_PATH, mask_path.split('/')[-1])\n",
    "#         shutil.move(mask_path, mask_test_path)    \n",
    "#     except:\n",
    "#         print(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}